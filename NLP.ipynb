{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Crq4sxRuNelY","executionInfo":{"status":"ok","timestamp":1717353263764,"user_tz":-120,"elapsed":71600,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}},"outputId":"d2611124-3dfe-428c-cd18-287747563085"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/11XUs_KemRo-9g_Wq5j0mL3xQwNLaexMX/TFM\n"]}],"source":["# Montamos la unidad Drive para acceder a los archivos de Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/TFM"]},{"cell_type":"code","source":["# Importamos las librer√≠as necesarias\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Cargamos el archivo csv en un DataFrame\n","df = pd.read_csv(\"vaccination_all_tweets.csv\")"],"metadata":{"id":"4BEPeZzRN8fz","executionInfo":{"status":"ok","timestamp":1717353270318,"user_tz":-120,"elapsed":6557,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Cargamos la librer√≠a y las funciones necesarias\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer, WordNetLemmatizer\n","from nltk.tag import pos_tag\n","from nltk.chunk import ne_chunk\n","import string\n","\n","\n","tweet= df['text']\n","# Mostramos la frase por pantalla\n","print(\"Frase a preprocesar:\\n\", tweet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVU2lBIeN8zE","executionInfo":{"status":"ok","timestamp":1717353272410,"user_tz":-120,"elapsed":2103,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}},"outputId":"0277d619-32c8-4ab8-f13d-a5779a5864e5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Frase a preprocesar:\n"," 0         Same folks said daikon paste could treat a cyt...\n","1         While the world has been on the wrong side of ...\n","2         #coronavirus #SputnikV #AstraZeneca #PfizerBio...\n","3         Facts are immutable, Senator, even when you're...\n","4         Explain to me again why we need a vaccine @Bor...\n","                                ...                        \n","228202    45+ #URBAN #Bengaluru #CovidVaccine Availabili...\n","228203    18-44 #BBMP #Bengaluru #CovidVaccine Availabil...\n","228204    18-44 #URBAN #Bengaluru #CovidVaccine Availabi...\n","228205    They promote their Vaccines leaving out the st...\n","228206    45+ #URBAN #Bengaluru #CovidVaccine Availabili...\n","Name: text, Length: 228207, dtype: object\n"]}]},{"cell_type":"code","source":["import re\n","# Limpiar texto\n","def clean_text(tweet):\n","    text = re.sub(r'http\\S+', '', tweet)  # Eliminar URLs\n","    text = re.sub(r'@\\w+', '', tweet)     # Eliminar menciones\n","    text = re.sub(r'#\\w+', '', tweet)     # Eliminar hashtags\n","    text = re.sub(r'\\d+', '', tweet)      # Eliminar n√∫meros\n","    text = re.sub(r'\\s+', ' ', tweet)     # Eliminar espacios adicionales\n","    text = text.lower()                   # Convertir a min√∫sculas\n","    return text\n","\n","# Aplicar la funci√≥n de limpieza a cada tweet\n","df['cleaned_tweet'] = df['text'].apply(clean_text)\n","\n","# Verificar la limpieza correcta de los datos\n","print(df[['text', 'cleaned_tweet']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEwvVO5hZDAB","executionInfo":{"status":"ok","timestamp":1717353277137,"user_tz":-120,"elapsed":4731,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}},"outputId":"12708a80-fc6b-4094-f774-08263c5580ee"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                text  \\\n","0  Same folks said daikon paste could treat a cyt...   \n","1  While the world has been on the wrong side of ...   \n","2  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n","3  Facts are immutable, Senator, even when you're...   \n","4  Explain to me again why we need a vaccine @Bor...   \n","\n","                                       cleaned_tweet  \n","0  same folks said daikon paste could treat a cyt...  \n","1  while the world has been on the wrong side of ...  \n","2  #coronavirus #sputnikv #astrazeneca #pfizerbio...  \n","3  facts are immutable, senator, even when you're...  \n","4  explain to me again why we need a vaccine @bor...  \n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","# Descargar el paquete punkt si no lo has hecho ya\n","nltk.download('punkt')\n","\n","# Suponiendo que `tweet` es una serie de pandas que contiene el texto que deseas tokenizar\n","# Convertir la serie de pandas en una cadena de texto\n","tweet_texto = tweet.values[0]  # Si `tweet` contiene solo un texto, extraerlo usando `.values[0]`\n","\n","todos_tokens = []\n","\n","# Iterar sobre cada tweet y tokenizarlo\n","for tweet in tweet:\n","    # Tokenizar el texto del tweet actual\n","    tokens = word_tokenize(tweet)\n","    # Agregar los tokens de este tweet a la lista de todos los tokens\n","    todos_tokens.extend(tokens)\n","\n","# Mostrar algunos tokens de ejemplo\n","print(\"Algunos tokens: \", todos_tokens[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-Vxql9KOmIW","executionInfo":{"status":"ok","timestamp":1717353337412,"user_tz":-120,"elapsed":60289,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}},"outputId":"43b75781-1b26-4e11-b444-e895daea3bc9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Algunos tokens:  ['Same', 'folks', 'said', 'daikon', 'paste', 'could', 'treat', 'a', 'cytokine', 'storm']\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer, WordNetLemmatizer\n","from nltk.tag import pos_tag\n","import string\n","import pandas as pd\n","\n","# Descargar los paquetes necesarios si no lo has hecho ya\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","nltk.download('punkt')\n","\n","# Lista para almacenar los resultados de preprocesamiento de cada tweet\n","tweets_preprocesados = []\n","\n","# Iterar sobre cada tweet y aplicar preprocesamiento\n","for tweet in df['text']:\n","    # Tokenizar el tweet\n","    tokens = word_tokenize(tweet)\n","\n","    # Eliminar las stop words\n","    stop_words = set(stopwords.words('english'))\n","    tokens_nosw = [token for token in tokens if token.lower() not in stop_words]\n","\n","    # Eliminar n√∫meros y signos de puntuaci√≥n\n","    filtered_tokens = [token for token in tokens_nosw if not token.isdigit() and not token in string.punctuation]\n","\n","    # Convertir todos los tokens a min√∫sculas\n","    clean_tokens = [token.lower() for token in filtered_tokens]\n","\n","    # Aplicar las t√©cnicas de stemming y lematizaci√≥n\n","    stemmer = SnowballStemmer('spanish')\n","    lemmatizer = WordNetLemmatizer()\n","    stemmed_tokens = [stemmer.stem(token) for token in clean_tokens]\n","    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in clean_tokens]\n","\n","    # Seleccionar tokens finales (en este caso, los tokens stemmatizados)\n","    final_tokens = stemmed_tokens.copy()\n","\n","    # Aplicar POS tagging\n","    pos_tags = pos_tag(final_tokens)\n","\n","    # Agregar los resultados a la lista de tweets preprocesados\n","    tweets_preprocesados.append({\n","        'original': tweet,\n","        'sin_stopwords': tokens_nosw,\n","        'sin_numeros_puntuacion': filtered_tokens,\n","        'minusculas': clean_tokens,\n","        'stemming': stemmed_tokens,\n","        'lematizacion': lemmatized_tokens,\n","        'pos_tags': pos_tags\n","    })\n","\n","# Convertir la lista de tweets preprocesados a un DataFrame\n","df_preprocesado = pd.DataFrame(tweets_preprocesados)\n","\n","# Mostrar el DataFrame preprocesado\n","print(df_preprocesado)"],"metadata":{"id":"FQjx_MpAYEht","executionInfo":{"status":"ok","timestamp":1717353837005,"user_tz":-120,"elapsed":499596,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"385f85b0-f90c-4e76-bb8d-a15743129e4a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["                                                 original  \\\n","0       Same folks said daikon paste could treat a cyt...   \n","1       While the world has been on the wrong side of ...   \n","2       #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n","3       Facts are immutable, Senator, even when you're...   \n","4       Explain to me again why we need a vaccine @Bor...   \n","...                                                   ...   \n","228202  45+ #URBAN #Bengaluru #CovidVaccine Availabili...   \n","228203  18-44 #BBMP #Bengaluru #CovidVaccine Availabil...   \n","228204  18-44 #URBAN #Bengaluru #CovidVaccine Availabi...   \n","228205  They promote their Vaccines leaving out the st...   \n","228206  45+ #URBAN #Bengaluru #CovidVaccine Availabili...   \n","\n","                                            sin_stopwords  \\\n","0       [folks, said, daikon, paste, could, treat, cyt...   \n","1       [world, wrong, side, history, year, ,, hopeful...   \n","2       [#, coronavirus, #, SputnikV, #, AstraZeneca, ...   \n","3       [Facts, immutable, ,, Senator, ,, even, 're, e...   \n","4       [Explain, need, vaccine, @, BorisJohnson, @, M...   \n","...                                                   ...   \n","228202  [45+, #, URBAN, #, Bengaluru, #, CovidVaccine,...   \n","228203  [18-44, #, BBMP, #, Bengaluru, #, CovidVaccine...   \n","228204  [18-44, #, URBAN, #, Bengaluru, #, CovidVaccin...   \n","228205  [promote, Vaccines, leaving, stronger, @, Russ...   \n","228206  [45+, #, URBAN, #, Bengaluru, #, CovidVaccine,...   \n","\n","                                   sin_numeros_puntuacion  \\\n","0       [folks, said, daikon, paste, could, treat, cyt...   \n","1       [world, wrong, side, history, year, hopefully,...   \n","2       [coronavirus, SputnikV, AstraZeneca, PfizerBio...   \n","3       [Facts, immutable, Senator, even, 're, ethical...   \n","4       [Explain, need, vaccine, BorisJohnson, MattHan...   \n","...                                                   ...   \n","228202  [45+, URBAN, Bengaluru, CovidVaccine, Availabi...   \n","228203  [18-44, BBMP, Bengaluru, CovidVaccine, Availab...   \n","228204  [18-44, URBAN, Bengaluru, CovidVaccine, Availa...   \n","228205  [promote, Vaccines, leaving, stronger, Russia,...   \n","228206  [45+, URBAN, Bengaluru, CovidVaccine, Availabi...   \n","\n","                                               minusculas  \\\n","0       [folks, said, daikon, paste, could, treat, cyt...   \n","1       [world, wrong, side, history, year, hopefully,...   \n","2       [coronavirus, sputnikv, astrazeneca, pfizerbio...   \n","3       [facts, immutable, senator, even, 're, ethical...   \n","4       [explain, need, vaccine, borisjohnson, matthan...   \n","...                                                   ...   \n","228202  [45+, urban, bengaluru, covidvaccine, availabi...   \n","228203  [18-44, bbmp, bengaluru, covidvaccine, availab...   \n","228204  [18-44, urban, bengaluru, covidvaccine, availa...   \n","228205  [promote, vaccines, leaving, stronger, russia,...   \n","228206  [45+, urban, bengaluru, covidvaccine, availabi...   \n","\n","                                                 stemming  \\\n","0       [folks, said, daikon, past, could, treat, cyto...   \n","1       [world, wrong, sid, history, year, hopefully, ...   \n","2       [coronavirus, sputnikv, astrazenec, pfizerbion...   \n","3       [facts, immut, senator, even, 're, ethically, ...   \n","4       [explain, need, vaccin, borisjohnson, matthanc...   \n","...                                                   ...   \n","228202  [45+, urban, bengaluru, covidvaccin, availabil...   \n","228203  [18-44, bbmp, bengaluru, covidvaccin, availabi...   \n","228204  [18-44, urban, bengaluru, covidvaccin, availab...   \n","228205  [promot, vaccin, leaving, strong, russi, vacci...   \n","228206  [45+, urban, bengaluru, covidvaccin, availabil...   \n","\n","                                             lematizacion  \\\n","0       [folk, said, daikon, paste, could, treat, cyto...   \n","1       [world, wrong, side, history, year, hopefully,...   \n","2       [coronavirus, sputnikv, astrazeneca, pfizerbio...   \n","3       [fact, immutable, senator, even, 're, ethicall...   \n","4       [explain, need, vaccine, borisjohnson, matthan...   \n","...                                                   ...   \n","228202  [45+, urban, bengaluru, covidvaccine, availabi...   \n","228203  [18-44, bbmp, bengaluru, covidvaccine, availab...   \n","228204  [18-44, urban, bengaluru, covidvaccine, availa...   \n","228205  [promote, vaccine, leaving, stronger, russia, ...   \n","228206  [45+, urban, bengaluru, covidvaccine, availabi...   \n","\n","                                                 pos_tags  \n","0       [(folks, NNS), (said, VBD), (daikon, NN), (pas...  \n","1       [(world, NN), (wrong, JJ), (sid, NN), (history...  \n","2       [(coronavirus, NN), (sputnikv, NN), (astrazene...  \n","3       [(facts, NNS), (immut, VBP), (senator, NN), (e...  \n","4       [(explain, RB), (need, MD), (vaccin, VB), (bor...  \n","...                                                   ...  \n","228202  [(45+, CD), (urban, JJ), (bengaluru, NN), (cov...  \n","228203  [(18-44, JJ), (bbmp, NN), (bengaluru, NN), (co...  \n","228204  [(18-44, JJ), (urban, JJ), (bengaluru, NN), (c...  \n","228205  [(promot, NN), (vaccin, NN), (leaving, VBG), (...  \n","228206  [(45+, CD), (urban, JJ), (bengaluru, NN), (cov...  \n","\n","[228207 rows x 7 columns]\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Aplicamos el m√©todo TF-IDF a las frases\n","tfidf = TfidfVectorizer()\n","tfidf_matrix = tfidf.fit_transform(df[\"text\"])\n","\n","# Mostramos el vocabulario (Corpus)\n","print(\"Vocabulario\", tfidf.get_feature_names_out())\n","\n","# Valor IDF para todas las palabras del vocabulario\n","print(\"IDF for all words in the vocabulary :\\n\", tfidf.idf_)\n","\n","# Mostramos la representaci√≥n TFIDF de algunos tokens\n","print('\\nRepresentaci√≥n TFIDF de \"{}\" es \\n{}'\n","      .format(df[\"text\"][0], tfidf_matrix[0].toarray()))\n","print('Representaci√≥n TFIDF de \"{}\" es \\n{}'\n","      .format(df[\"text\"][1], tfidf_matrix[1].toarray()))\n","print('Representaci√≥n TFIDF de \"{}\" es \\n{}'\n","      .format(df[\"text\"][2],tfidf_matrix[2].toarray()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FP2sQ5Cvff1E","executionInfo":{"status":"ok","timestamp":1717353845824,"user_tz":-120,"elapsed":8823,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}},"outputId":"76845593-e28c-427b-8446-c0c64ae9ade6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulario ['00' '000' '0000' ... 'ùü≥ùüÆ' 'ùüªùü∫ùüæ' 'ùüøùü∂ùüø']\n","IDF for all words in the vocabulary :\n"," [ 5.99977462  5.66293092 11.95171841 ... 12.64486559 12.64486559\n"," 12.64486559]\n","\n","Representaci√≥n TFIDF de \"Same folks said daikon paste could treat a cytokine storm #PfizerBioNTech https://t.co/xeHhIMg1kF\" es \n","[[0. 0. 0. ... 0. 0. 0.]]\n","Representaci√≥n TFIDF de \"While the world has been on the wrong side of history this year, hopefully, the biggest vaccination effort we've ev‚Ä¶ https://t.co/dlCHrZjkhm\" es \n","[[0. 0. 0. ... 0. 0. 0.]]\n","Representaci√≥n TFIDF de \"#coronavirus #SputnikV #AstraZeneca #PfizerBioNTech #Moderna #Covid_19 Russian vaccine is created to last 2-4 years‚Ä¶ https://t.co/ieYlCKBr8P\" es \n","[[0. 0. 0. ... 0. 0. 0.]]\n"]}]},{"cell_type":"code","source":["# Guardar el DataFrame procesado\n","df.to_csv('tweets_processed.csv', index=False)\n","\n","# Crear y guardar el DataFrame de palabras clave (vocabulario)\n","vocab_df = pd.DataFrame(tfidf.get_feature_names_out(), columns=['keywords'])\n","vocab_df.to_csv('keywords.csv', index=False)\n"],"metadata":{"id":"t4KCfVMbgocM","executionInfo":{"status":"ok","timestamp":1717353855488,"user_tz":-120,"elapsed":9667,"user":{"displayName":"Olga Ib√°√±ez","userId":"09676347011068199341"}}},"execution_count":8,"outputs":[]}]}